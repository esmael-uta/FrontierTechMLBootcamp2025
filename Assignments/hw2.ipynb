{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e545c6c4",
   "metadata": {},
   "source": [
    "Assignment: Binary Classification with Logistic Regression\n",
    "\n",
    "In this assignment, you will work with the Iris dataset to perform binary classification using logistic regression. The Iris dataset contains samples from three different species of iris flowers, but for this assignment, you will focus on classifying Iris Setosa (class 0) versus the combination of the other two classes (class 1).\n",
    "\n",
    "Here are the steps you need to follow for this assignment:\n",
    "\n",
    "Step 1: Load the Iris dataset\n",
    "\n",
    "Load the Iris dataset using sklearn.datasets.load_iris().\n",
    "Extract the feature matrix X and the target vector y.\n",
    "\n",
    "\n",
    "Step 2: Preprocess the data\n",
    "\n",
    "To convert this problem into binary classification, create a new target vector y_binary where Iris Setosa (class 0) is labeled as 1, and the other two classes are labeled as 0.\n",
    "\n",
    "\n",
    "Step 3: Split the dataset\n",
    "\n",
    "Split the dataset into training and testing sets using train_test_split() from sklearn.model_selection.\n",
    "Use 80% of the data for training and 20% for testing. Set the random_state to ensure reproducibility.\n",
    "\n",
    "Step 4: Define the cost function (logistic loss)\n",
    "\n",
    "Implement the logistic loss function, which calculates the cost of your model's predictions.\n",
    "\n",
    "Step 5: Define the training function\n",
    "\n",
    "Implement a training function that uses gradient descent to optimize the logistic regression model.\n",
    "The function should take input data, learning rate, number of iterations, and regularization parameter as arguments.\n",
    "\n",
    "Step 6: Train the model\n",
    "\n",
    "Use the training function to train your logistic regression model on the training data.\n",
    "Obtain the weight vector W and bias term b.\n",
    "\n",
    "\n",
    "Step 7: Define the prediction function\n",
    "\n",
    "Implement a prediction function that takes input data and the trained model's weights and bias.\n",
    "The prediction function should use the logistic sigmoid function to make binary predictions (0 or 1).\n",
    "\n",
    "\n",
    "Step 8: Predict on the test set\n",
    "\n",
    "Use the prediction function to predict the classes for the test set X_test using the obtained weights and bias.\n",
    "\n",
    "\n",
    "Step 9: Evaluate the model's performance\n",
    "\n",
    "Calculate the accuracy of your model using accuracy_score() from sklearn.metrics.\n",
    "Generate the confusion matrix using confusion_matrix() from sklearn.metrics.\n",
    "Generate the classification report using classification_report() from sklearn.metrics.\n",
    "Print out the accuracy, confusion matrix, and classification report to evaluate your model's performance.\n",
    "Make sure to comment your code and provide explanations for each step. This assignment will help you understand the basics of binary classification, logistic regression, and how to evaluate the performance of your model using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f956686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights (w): [ 0.25454214  0.92927989 -1.46966825 -0.65684729]\n",
      "Trained Bias (b): 0.170502930799558\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[20  0]\n",
      " [ 0 10]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def logistic_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the logistic loss (cross-entropy loss).\n",
    "\n",
    "    Args:\n",
    "        y_true (numpy.ndarray): True labels, shape (n,).\n",
    "        y_pred (numpy.ndarray): Predicted probabilities, shape (n,).\n",
    "\n",
    "    Returns:\n",
    "        float: The logistic loss.\n",
    "    \"\"\"\n",
    "    # Avoid division by zero and log of zero by clipping predictions to a small range\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    loss = -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "def train_logistic_regression(X, y, learning_rate, num_iterations, regularization_param=0.0):\n",
    "    \"\"\"\n",
    "    Trains a logistic regression model using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix, shape (n, m).\n",
    "        y (numpy.ndarray): True labels, shape (n,).\n",
    "        learning_rate (float): Learning rate for gradient descent.\n",
    "        num_iterations (int): Number of iterations for gradient descent.\n",
    "        regularization_param (float, optional): L2 regularization parameter. Defaults to 0.0.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (w, b, cost_history)\n",
    "            w (numpy.ndarray): Trained weights, shape (m,).\n",
    "            b (float): Trained bias.\n",
    "            cost_history (list): List of cost values during training.\n",
    "    \"\"\"\n",
    "    n, m = X.shape\n",
    "    w = np.zeros(m)  # Initialize weights\n",
    "    b = 0            # Initialize bias\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        # Compute predictions using the sigmoid function\n",
    "        z = np.dot(X, w) + b\n",
    "        y_pred = 1 / (1 + np.exp(-z))\n",
    "\n",
    "        # Compute the cost (logistic loss)\n",
    "        cost = logistic_loss(y, y_pred)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Compute the gradients\n",
    "        dw = (1 / n) * (np.dot(X.T, (y_pred - y)) + regularization_param * w) #L2 regularization\n",
    "        db = (1 / n) * np.sum(y_pred - y)\n",
    "\n",
    "        # Update the weights and bias\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "    return w, b, cost_history\n",
    "\n",
    "\n",
    "\n",
    "def predict(X, w, b):\n",
    "    \"\"\"\n",
    "    Predicts binary labels for the given data using the trained logistic regression model.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.ndarray): Feature matrix, shape (n, m).\n",
    "        w (numpy.ndarray): Trained weights, shape (m,).\n",
    "        b (float): Trained bias.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Predicted labels, shape (n,).\n",
    "    \"\"\"\n",
    "    z = np.dot(X, w) + b\n",
    "    y_pred_prob = 1 / (1 + np.exp(-z))  # Sigmoid function\n",
    "    y_pred = (y_pred_prob >= 0.5).astype(int)  # Convert probabilities to binary labels\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load the Iris dataset\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "    # Step 2: Preprocess the data for binary classification\n",
    "    # Iris Setosa (class 0) is labeled as 1, others as 0\n",
    "    y_binary = (y == 0).astype(int)\n",
    "\n",
    "    # Step 3: Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Step 4: Define the cost function (logistic loss) - Already defined as logistic_loss()\n",
    "\n",
    "    # Step 5: Define the training function - Already defined as train_logistic_regression()\n",
    "\n",
    "    # Step 6: Train the model\n",
    "    learning_rate = 0.01\n",
    "    num_iterations = 1000\n",
    "    regularization_param = 0.01  # Example L2 regularization parameter\n",
    "    w, b, cost_history = train_logistic_regression(X_train, y_train, learning_rate, num_iterations, regularization_param)\n",
    "\n",
    "    print(\"Trained Weights (w):\", w)\n",
    "    print(\"Trained Bias (b):\", b)\n",
    "\n",
    "    # Step 7: Define the prediction function - Already defined as predict()\n",
    "\n",
    "    # Step 8: Predict on the test set\n",
    "    y_pred = predict(X_test, w, b)\n",
    "\n",
    "    # Step 9: Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Confusion Matrix:\\n\", confusion)\n",
    "    print(\"Classification Report:\\n\", classification_report_str)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e65aa1",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "Perfect Accuracy: The model achieved an accuracy of 1.0, indicating that it correctly classified all samples in the test set.\n",
    "\n",
    "Confusion Matrix: The confusion matrix shows that there were no false positives or false negatives. All 20 samples of class 0 and all 10 samples of class 1 were correctly predicted.\n",
    "Classification Report: The precision, recall, and f1-score are all 1.0 for both classes, further confirming the perfect classification performance.\n",
    "\n",
    "In summary, the logistic regression model successfully learned to distinguish Iris Setosa from the other two species in this binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d500c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
